{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94517ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "\n",
    "class GPT2:\n",
    "    id = 1\n",
    "\n",
    "    def __init__(self, modelName=None) -> None:\n",
    "        if modelName:\n",
    "            self.name = modelName\n",
    "        else:\n",
    "            self.name = f\"gpt2_{GPT2.id}\"\n",
    "            GPT2.id += 1\n",
    "\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "        self.dataloader = DataLoader\n",
    "\n",
    "    def init_data_loader(self, data, max_length=280, batch_size=32, shuffle=True, pin_memory=True, num_workers=0):\n",
    "        self.dataset = __TweetDataset(\n",
    "            data, tokenizer=self.tokenizer, max_length=max_length)\n",
    "\n",
    "        self.dataloader = DataLoader(\n",
    "            self.dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=pin_memory, num_workers=num_workers)\n",
    "\n",
    "    def init_optimizer(self, lr=1e-5, num_warmup_steps=100, num_training_steps=1000):\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr)\n",
    "\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self, epochs=1, max_grad_norm=1.0):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "\n",
    "        self.model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch in self.dataloader:\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "\n",
    "                # forward pass\n",
    "                outputs = self.model(input_ids, labels=input_ids)\n",
    "                loss = outputs.loss\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Apply gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.model.parameters(), max_grad_norm)\n",
    "\n",
    "                # update learning rate\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            epoch_loss = 0\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs}, Average Loss: {epoch_loss / len(self.dataloader)}\")\n",
    "            torch.save(self.model.state_dict(),\n",
    "                       f\"{self.name}{epoch + 1}.pth\")\n",
    "\n",
    "    def save_model(self, path,):\n",
    "        self.model.save_pretrained(path)\n",
    "\n",
    "    def generate_text(self, prompt=None):\n",
    "        if prompt:\n",
    "            generated_tweets = self.model.generate(prompt,\n",
    "                                                   max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "        else:\n",
    "            generated_tweets = self.model.generate(\n",
    "                max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "\n",
    "        decoded_tweets = self.tokenizer.decode(\n",
    "            generated_tweets[0], skip_special_tokens=True)\n",
    "        return decoded_tweets\n",
    "\n",
    "\n",
    "class __TweetDataset(Dataset):\n",
    "    def __init__(self, tweets, tokenizer, max_length=280):\n",
    "        self.encodings = tokenizer(\n",
    "            tweets, truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
